name: Baidu SEO Push

# 触发条件：当 main 分支有 push 操作，或者每天定时触发
on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 23 * * *' # 每天北京时间早上7点自动跑一次（UTC 23:00）
  workflow_dispatch:

jobs:
  baidu-push:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Fetch and Push URLs to Baidu
        env:
          BAIDU_TOKEN: ${{ secrets.BAIDU_TOKEN }}
          SITE_URL: "https://halcyon666.top"
        run: |
          # 1. 从 gh-pages 分支获取 sitemap.xml（避免 Cloudflare 拦截）
          echo "Fetching sitemap from gh-pages branch..."
          git fetch origin gh-pages
          git show origin/gh-pages:sitemap.xml > sitemap.xml

          # 验证获取到的是有效 XML 而非 Cloudflare 拦截页
          if head -c 5 sitemap.xml | grep -q '<?xml'; then
            echo "Valid sitemap.xml obtained."
          else
            echo "ERROR: sitemap.xml is not valid XML. Content preview:"
            head -c 200 sitemap.xml
            exit 1
          fi

          # 2. 提取 sitemap 中的所有 URL（用 grep+sed，无需安装 xmllint）
          echo "Extracting URLs..."
          grep -o '<loc>[^<]*</loc>' sitemap.xml | sed 's/<loc>//g;s/<\/loc>//g' > urls.txt

          COUNT=$(wc -l < urls.txt)
          echo "Found $COUNT URLs to push."

          # 3. 调用百度 API 推送
          if [ "$COUNT" -gt 0 ]; then
            echo "Pushing to Baidu..."
            result=$(curl -s -H 'Content-Type:text/plain' --data-binary @urls.txt "http://data.zz.baidu.com/urls?site=$SITE_URL&token=$BAIDU_TOKEN")
            echo "Baidu Response: $result"
          else
            echo "No URLs found in sitemap."
            exit 1
          fi