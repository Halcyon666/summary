---
id: level-1-ai-native
title: Level 1 - AI-Native 工作流与基础设施
sidebar_label: Level 1 - AI-Native 工作流
sidebar_position: 2
description: 建立 AI 优先的开发习惯,搭建本地 AI 基础设施
tags:
- ai
- prompt-engineering
- level-1
last_update:
  date: '2026-01-25'
  author: halcyon666
---

# 阶段一: AI-Native 工作流与基础设施 (Level 1)

**周期**: 第 1-2 周  
**核心目标**: 建立 AI 优先的开发习惯,搭建本地 AI 基础设施

## 前置能力要求

- 掌握至少一门编程语言 (Python/Java/JavaScript)
- 了解基本的命令行操作和 Docker 使用

## 为什么需要这个阶段

AI 工具不是简单的"代码补全",而是要**重构整个开发生命周期**。必须先建立 AI-Native 的工作习惯,才能在后续阶段高效学习复杂的 AI 技术。

## ⭐ 核心能力 1: IDE 掌控力与 Prompt 工程基础

### ⭐ 目标

强迫自己**不写** Boilerplate Code,通过 Prompt 驱动代码生成

### 实践标准

**量化目标** (可验证的成功标准):
- **项目级**: 在一个包含 10 个文件的项目中,至少 8 个文件 (80%) 的初始版本由 AI 生成
- **文件级**: 每个文件中样板代码 (imports、类定义、基础 CRUD 方法) 100% 由 AI 生成
- ⭐ **迭代效率**: 平均每个文件通过 ≤ 3 次 Prompt 迭代达到可用状态

**工作流** (强制执行的三步法):
1. **生成**: 使用 Cursor/Windsurf 的 `Cmd+K` 或 `Composer`,通过自然语言描述生成代码
2. ⭐ **验证**: 如果生成的代码不符合要求,**禁止手动修改**,而是分析问题并修改 Prompt
3. ⭐ **沉淀**: 将有效的 Prompt 模板保存到个人 `.cursorrules` 文件,包含项目代码规范和最佳实践

### ⭐ Prompt 模板示例

**模板 1: DDD 架构代码生成**

```
你是一位精通领域驱动设计 (DDD) 的 Java 架构师。

需求: 为 [领域名称] 创建聚合根实体类。

要求:
1. 使用 Java 17 语法
2. 遵循 DDD 原则: 实体包含业务逻辑,不是贫血模型
3. 包含: 实体 ID、值对象、领域事件
4. 使用 Lombok 注解减少样板代码
5. 添加详细的 Javadoc 注释

领域上下文:
- 实体名称: [User]
- 核心属性: [userId, email, profile]
- 业务规则: [email 必须唯一,profile 可选]

请生成完整的实体类代码。
```

**反面案例**:
```
❌ "帮我写一个 User 类"
   → 太模糊,没有说明架构风格、技术栈、业务规则
```

**⭐ 模板 2: 错误调试**

```
你是一位经验丰富的 Python 调试专家。

错误上下文:
- 项目: [FastAPI + Milvus RAG 系统]
- 运行环境: [Python 3.11, Docker]
- 错误发生时机: [向 Milvus 插入向量时]

错误日志:
```
[粘贴完整的 Stack Trace]
```

相关代码:
```python
[粘贴出错的代码片段,前后各 10 行]
```

请分析:
1. Root Cause (根本原因)
2. 为什么会发生这个错误
3. 提供 3 个可能的解决方案,按推荐优先级排序
4. 如何预防类似错误
```

**反面案例**:
```
❌ "这个错误怎么解决: [只粘贴一行错误信息]"
   → 缺少上下文,AI 无法准确分析
```

### 质量验证标准

**能力验证清单** (必须全部达成):
- [ ] **代码生成能力**: 能够通过自然语言描述生成 80% 以上的样板代码,无需手动补充
- [ ] ⭐ **Prompt 库建设**: 建立个人 Prompt Library,包含至少 5 个模板 (代码生成、调试、重构、测试、文档各 1 个)
- [ ] ⭐ **迭代优化能力**: 能够通过迭代 Prompt (而非手动修改代码) 来纠正 AI 生成的代码,平均迭代次数 ≤ 3 次
- [ ] **调试准确率**: 在 10 次错误调试中,AI 能够在前 3 个建议中给出正确 Root Cause 的次数 ≥ 7 次 (70% 准确率)

**验证方法**: 选择一个小型项目 (如 Todo List API),从零开始使用 AI 生成所有代码,记录生成比例和迭代次数

## ⭐ 核心能力 2: 基础设施搭建

### ⭐ 本地模型部署

**Ollama 部署 Llama 3.1 / Qwen 2.5 (8B)**

**量化技术理解** (必须掌握的核心概念):
- **Q4_0 (4-bit 量化)**: 每个参数用 4 位存储,8B 模型约 4.5GB,适合 8GB 显存的消费级显卡
- **FP16 (16-bit 半精度)**: 每个参数用 16 位存储,8B 模型约 16GB,需要专业级显卡
- **权衡**: Q4_0 损失约 1-2% 精度,但显存占用减少 75%,适合本地开发

**显存占用计算公式**:
```
总显存 = (模型参数量 × 量化位数 / 8) + 上下文缓存
示例: 8B 模型 Q4_0 = (8 × 10^9 × 4 / 8) / 10^9 ≈ 4GB + 0.5GB (上下文) = 4.5GB
```

**实战验证**: 运行 `ollama run qwen2.5:8b` 并使用 `nvidia-smi` 或 `Activity Monitor` 验证显存占用

### 连接协议: MCP (Model Context Protocol)

**实战任务**: 编写一个 Python MCP Client,让 Ollama 调用本地的 `add_numbers` 工具

```python
# 示例: MCP Client 基础结构
from mcp import Client

client = Client()
client.register_tool("add_numbers", lambda a, b: a + b)
response = client.query("What is 123 + 456?")
print(response)  # 应该调用 add_numbers 工具
```

### ⭐ 容器化环境

使用 Docker Compose 部署本地服务:
- ⭐ Milvus (向量数据库)
- Dify (低代码 AI 平台)
- Neo4j (知识图谱,可选)

## 核心能力 3: Python 数据栈基础

**为什么需要 Python**: AI 生态主要基于 Python,即使你是 Java 开发者,也需要掌握 Python 来处理 AI 推理逻辑

**学习重点**:
- **Pandas/NumPy**: 掌握向量化计算 (为 Embedding 打基础)
- **PyTorch 基础**:
  - Tensor 维度操作 `[Batch, Seq, Dim]`
  - `.to('cuda')` 设备管理
  - 加载预训练模型 (不需要从零训练)

:::tip 工具关系理解
- **NumPy**: 在 CPU 上处理数字矩阵
- **PyTorch**: 在 GPU 上处理数字矩阵,并且多了"自动求导"(神经网络学习的核心)
- **模型 (LLM/BERT)**: 本质上就是用 PyTorch 写的一个超级复杂的数学公式
:::

## 阶段产出标准

**必须完成的交付物** (作为进入 Level 2 的前置条件):

**基础设施层**:
- [ ] ⭐ 成功部署本地 Ollama 并运行 8B 模型,能够通过 API 调用获得响应
- [ ] 完成至少 1 个 MCP Client 示例,实现 Ollama 调用本地工具函数
- [ ] ⭐ 使用 Docker Compose 成功部署至少 2 个 AI 相关服务 (Milvus + Dify 或 Neo4j)

**Prompt 工程层**:
- [ ] ⭐ 建立个人 Prompt Library,包含至少 5 个模板,覆盖: 代码生成、调试、重构、测试、文档
- [ ] ⭐ 配置完成 Cursor/Windsurf (包含 `.cursorrules` 文件),并在一个小项目中实践 AI 生成 80% 代码

**能力验证**:
- [ ] 能够独立完成一个小型项目 (如 RESTful API) 的搭建,80% 代码由 AI 生成
- [ ] ⭐ 能够通过 Prompt 迭代解决至少 3 个实际编码问题,无需手动修改代码

**时间检查点**: 如果超过 2 周仍未完成,需要重新评估学习方法或降低项目复杂度

---

**下一阶段**: [Level 2 - RAG 应用开发与异构系统架构](./level-2-rag)
