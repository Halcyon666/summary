---
id: level-1-ai-native
title: Level 1 - AI-Native 工作流与基础设施
sidebar_label: Level 1 - AI-Native 工作流
sidebar_position: 2
description: 建立 AI 优先的开发习惯,搭建本地 AI 基础设施
tags:
- ai
- prompt-engineering
- level-1
last_update:
  date: '2026-01-25'
  author: halcyon666
---

# 阶段一: AI-Native 工作流与基础设施 (Level 1)

**周期**: 第 1-2 周  
**核心目标**: 建立 AI 优先的开发习惯,搭建本地 AI 基础设施

## 前置能力要求

- 掌握至少一门编程语言 (Python/Java/JavaScript)
- 了解基本的命令行操作和 Docker 使用

## 为什么需要这个阶段

AI 工具不是简单的"代码补全",而是要**重构整个开发生命周期**。必须先建立 AI-Native 的工作习惯,才能在后续阶段高效学习复杂的 AI 技术。

## ⭐ 核心能力 1: IDE 掌控力与 Prompt 工程基础

### ⭐ 目标

强迫自己**不写** Boilerplate Code,通过 Prompt 驱动代码生成

### 实践标准

**量化目标** (可验证的成功标准):
- **项目级**: 在一个包含 10 个文件的项目中,至少 8 个文件 (80%) 的初始版本由 AI 生成
- **文件级**: 每个文件中样板代码 (imports、类定义、基础 CRUD 方法) 100% 由 AI 生成
- ⭐ **迭代效率**: 平均每个文件通过 ≤ 3 次 Prompt 迭代达到可用状态

**工作流** (强制执行的三步法):
1. **生成**: 使用 Cursor/Windsurf 的 `Cmd+K` 或 `Composer`,通过自然语言描述生成代码
2. ⭐ **验证**: 如果生成的代码不符合要求,**禁止手动修改**,而是分析问题并修改 Prompt
3. ⭐ **沉淀**: 将有效的 Prompt 模板保存到个人 `.cursorrules` 文件,包含项目代码规范和最佳实践

### ⭐ Prompt 模板示例

<details>
<summary>模板 1: DDD 架构代码生成</summary>
```markdown
# Role: DDD Java 聚合根代码生成专家

## Profile
- author: LangGPT
- version: 1.0
- language: 中文
- description: 
你是一名精通领域驱动设计（DDD）的高级 Java 架构师，擅长将业务规则建模为高内聚、强约束的聚合根实体，并输出可直接用于生产环境的代码。

## Skills
- 深入理解 DDD 中的聚合根、实体、值对象、领域事件
- 熟练使用 Java 17 进行领域建模
- 能将业务规则转化为实体内部的不变性约束
- 使用 Lombok 与现代 Java 语法编写简洁、可维护代码

## Background
当前需要基于领域驱动设计，为指定领域上下文建模一个聚合根实体。  
该实体必须体现业务规则与行为，而非简单的数据载体（避免贫血模型）。

## Goals
- 生成一个符合 DDD 原则的聚合根实体类
- 实体需内聚业务逻辑，并通过方法维护自身不变性
- 代码结构清晰，可作为领域层核心模型使用

## Rules
1. 使用 **Java 17** 语法
2. 聚合根必须是一个 **富领域模型**，包含必要的业务方法
3. 必须显式建模：
   - 实体 ID（作为值对象或强类型）
   - 至少一个值对象
   - 至少一个领域事件（仅定义，不涉及基础设施）
4. 使用 **Lombok**（如 `@Getter`, `@EqualsAndHashCode` 等）减少样板代码
5. 为类、核心属性、关键方法编写 **详细 Javadoc**
6. 不引入持久化框架注解（如 JPA）
7. 输出内容 **仅包含完整的 Java 代码**

## Workflows
1. 分析领域上下文与业务规则
2. 识别聚合根边界与核心不变性
3. 设计实体、值对象与领域事件
4. 输出完整、可读、符合 DDD 的实体类代码

## Input
- 领域上下文:
  - 实体名称: User
  - 核心属性:
    - userId（唯一标识）
    - email（必须唯一）
    - profile（可选值对象）
  - 业务规则:
    - email 在系统中必须唯一（由领域层语义保证）
    - profile 可为空，但一旦存在必须完整有效

## OutputFormat
- 单个 Java 文件
- 包含：
  - 聚合根实体 `User`
  - 必要的值对象
  - 至少一个领域事件类

## Init
请基于以上约束，生成 **完整的 User 聚合根实体类代码**。
```
</details>

**反面案例**:
```
❌ "帮我写一个 User 类"
   → 太模糊,没有说明架构风格、技术栈、业务规则
```


<details>
<summary>⭐ 模板 2: 错误调试</summary>
```markdown
你是一位经验丰富的 Python 调试专家，精通 FastAPI 与 Milvus 相关开发。

## 项目和环境信息
- 项目类型: FastAPI + Milvus RAG 系统
- Python 版本: 3.11
- 运行环境: Docker
- 错误触发时机: 向 Milvus 插入向量时

## 错误日志
请在下面完整粘贴 Stack Trace:
---
[粘贴完整 Stack Trace]
---

## 相关代码
请提供出错代码片段（建议前后各 10 行）：
---
[粘贴代码片段]
---

## 分析需求
请针对以上信息进行详细分析，包括：

1. **根本原因 (Root Cause)**：请明确指出导致错误的核心原因。
2. **错误发生原因**：解释为什么会出现此错误，包括可能的环境、依赖或逻辑问题。
3. **解决方案**：提供 3 个可行方案，并按推荐优先级排序，说明每个方案的优缺点。
4. **预防建议**：针对类似问题给出最佳实践或防护措施。

```
</details>

**反面案例**:
```
❌ "这个错误怎么解决: [只粘贴一行错误信息]"
   → 缺少上下文,AI 无法准确分析
```

### 质量验证标准

**能力验证清单** (必须全部达成):
- [ ] **代码生成能力**: 能够通过自然语言描述生成 80% 以上的样板代码,无需手动补充
- [ ] ⭐ **Prompt 库建设**: 建立个人 Prompt Library,包含至少 5 个模板 (代码生成、调试、重构、测试、文档各 1 个)
- [ ] ⭐ **迭代优化能力**: 能够通过迭代 Prompt (而非手动修改代码) 来纠正 AI 生成的代码,平均迭代次数 ≤ 3 次
- [ ] **调试准确率**: 在 10 次错误调试中,AI 能够在前 3 个建议中给出正确 Root Cause 的次数 ≥ 7 次 (70% 准确率)

**验证方法**: 选择一个小型项目 (如 Todo List API),从零开始使用 AI 生成所有代码,记录生成比例和迭代次数

## ⭐ 核心能力 2: 基础设施搭建

### ⭐ 本地模型部署

**Ollama 部署 Llama 3.1 / Qwen 2.5 (8B)**

**量化技术理解** (必须掌握的核心概念):
- **Q4_0 (4-bit 量化)**: 每个参数用 4 位存储,8B 模型约 4.5GB,适合 8GB 显存的消费级显卡
- **FP16 (16-bit 半精度)**: 每个参数用 16 位存储,8B 模型约 16GB,需要专业级显卡
- **权衡**: Q4_0 损失约 1-2% 精度,但显存占用减少 75%,适合本地开发

**显存占用计算公式**:
```
总显存 = (模型参数量 × 量化位数 / 8) + 上下文缓存
示例: 8B 模型 Q4_0 = (8 × 10^9 × 4 / 8) / 10^9 ≈ 4GB + 0.5GB (上下文) = 4.5GB
```

**实战验证**: 运行 `ollama run qwen2.5:8b` 并使用 `nvidia-smi` 或 `Activity Monitor` 验证显存占用

### 连接协议: MCP (Model Context Protocol)

**实战任务**: 编写一个 Python MCP Client,让 Ollama 调用本地的 `add_numbers` 工具

```python
# 示例: MCP Client 基础结构
from mcp import Client

client = Client()
client.register_tool("add_numbers", lambda a, b: a + b)
response = client.query("What is 123 + 456?")
print(response)  # 应该调用 add_numbers 工具
```

### ⭐ 容器化环境

使用 Docker Compose 部署本地服务:
- ⭐ Milvus (向量数据库)
- Dify (低代码 AI 平台)
- Neo4j (知识图谱,可选)

## 核心能力 3: Python 数据栈基础

**为什么需要 Python**: AI 生态主要基于 Python,即使你是 Java 开发者,也需要掌握 Python 来处理 AI 推理逻辑

**学习重点**:
- **Pandas/NumPy**: 掌握向量化计算 (为 Embedding 打基础)
- **PyTorch 基础**:
  - Tensor 维度操作 `[Batch, Seq, Dim]`
  - `.to('cuda')` 设备管理
  - 加载预训练模型 (不需要从零训练)

:::tip 工具关系理解
- **NumPy**: 在 CPU 上处理数字矩阵
- **PyTorch**: 在 GPU 上处理数字矩阵,并且多了"自动求导"(神经网络学习的核心)
- **模型 (LLM/BERT)**: 本质上就是用 PyTorch 写的一个超级复杂的数学公式
:::

## 阶段产出标准

**必须完成的交付物** (作为进入 Level 2 的前置条件):

**基础设施层**:
- [X] ⭐ 成功部署本地 Ollama 并运行 8B 模型,能够通过 API 调用获得响应
- [X] 完成至少 1 个 MCP Client 示例,实现 Ollama 调用本地工具函数
- [ ] ⭐ 使用 Docker Compose 成功部署至少 2 个 AI 相关服务 (Milvus + Dify 或 Neo4j)

**Prompt 工程层**:
- [ ] ⭐ 建立个人 Prompt Library,包含至少 5 个模板,覆盖: 代码生成、调试、重构、测试、文档
- [ ] ⭐ 配置完成 Cursor/Windsurf (包含 `.cursorrules` 文件),并在一个小项目中实践 AI 生成 80% 代码

**能力验证**:
- [ ] 能够独立完成一个小型项目 (如 RESTful API) 的搭建,80% 代码由 AI 生成
- [ ] ⭐ 能够通过 Prompt 迭代解决至少 3 个实际编码问题,无需手动修改代码

**时间检查点**: 如果超过 2 周仍未完成,需要重新评估学习方法或降低项目复杂度

---

**下一阶段**: [Level 2 - RAG 应用开发与异构系统架构](./level-2-rag)
