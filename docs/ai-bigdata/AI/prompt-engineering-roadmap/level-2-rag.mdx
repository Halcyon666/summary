---
id: level-2-rag
title: Level 2 - RAG 应用开发与异构系统架构
sidebar_label: Level 2 - RAG 应用开发
sidebar_position: 3
description: 掌握检索增强生成 (RAG),理解 Java-Python 异构系统通信,建立评估体系
tags:
- ai
- rag
- level-2
last_update:
  date: '2026-01-27'
  author: halcyon666
---

# 阶段二: RAG 应用开发与异构系统架构 (Level 2)

**周期**: 第 3-5 周  
**核心目标**: 掌握检索增强生成 (RAG),理解 Java-Python 异构系统通信,建立评估体系

## 前置能力要求

- ✅ 已掌握 Python 基础和 AI 工具使用 (Level 1)
- ✅ 已建立 AI-Native 开发习惯
- ✅ 已部署本地 Ollama 和向量数据库

## 为什么需要这个阶段

RAG 是 AI 应用的核心能力,Agent 的智能决策依赖于 RAG 提供的知识检索能力。必须先掌握"如何让 AI 获取外部知识",才能进入"如何让 AI 自主决策"。

## ⭐ 核心能力 1: 双轨 RAG 实现

### ⭐ 平台流: Dify 企业级实战 (80% 场景)

**策略: "扩展,不深读"**

将 Dify 视为"黑盒"或"组件",专注于如何**扩展**它:

- **Custom Tooling**: 编写 Python API 供 Dify 调用,让 Java 系统与 Dify 通信
- **Workflow Orchestration**: 掌握 Dify 的 Workflow 节点,理解如何在节点间传递变量
- **为什么跳过源码?** Dify 基于 Flask/Next.js/PostgreSQL 复杂栈,除非修复 bug,时间更应花在 **LangGraph** (复杂逻辑) 或 **Milvus** (数据侧)

**⭐ 实战任务**:
1. 使用 Docker 部署 Dify
2. 接入本地 Ollama
3. ⭐ 搭建企业知识库: 上传 PDF,配置 Embedding 模型,测试混合检索
4. 发布 Web 端对话机器人

### ⭐ 核心实战：Dify 自定义工具 (Custom Tool)

利用你的 **Spring Boot** 优势，增强 Agent 的手脚。

#### 任务描述
Dify 无法直接获取你公司的实时数据（如服务器状态、数据库库存），你需要写一个 API 给它调用。

#### 实施步骤
1.  **后端开发 (Spring Boot)**：
    * 编写一个接口 `GET /api/v1/system/status`，返回 JSON 格式的 CPU/内存/业务数据。
    * 生成 **OpenAPI (Swagger)** 描述文档。
2.  **Dify 集成**：
    * 在 Dify "工具" 页签 -> "创建自定义工具"。
    * 导入你的 OpenAPI Schema。
3.  **Agent 编排**：
    * 在 Prompt 中开启该工具。
    * 测试提问：“现在的系统负载怎么样？” -> Agent 自动调用 Java 接口 -> 回答。


### 代码流: 手写 RAG 链路 (20% 深度定制)

**核心组件**:
- ⭐ **Milvus**: 部署并理解 HNSW 索引原理
- ⭐ **Embedding**: 使用 `sentence-transformers` 加载 `bge-base-zh`

**⭐ 高级切片策略**:

1. ⭐ **Parent-Child Indexing**
   - 索引小切片 (128 tokens,精准检索)
   - 返回父切片 (512 tokens,保留上下文)
   - 解决"检索精准但上下文不足"的问题

2. **HyDE (假设性文档嵌入)**
   - 让 LLM 先生成"假想答案"
   - 用假答案的 Embedding 去搜文档
   - 解决"问题与文档语义不匹配"的问题

**⭐ 实战代码链路**:
```
读取 PDF → 高级切片 → 向量化 → 存入 Milvus → 检索 → 组装 Prompt → LLM 回答
```

### ⭐ 早期评估 (Early Eval) - 关键!

**⭐ 核心理念**: 将 RAG 评估视为**单元测试**

**⭐ Golden Dataset 构建方法**:

1. **选择代表性问题** (10-20 个):
   - 覆盖不同难度: 简单事实查询、复杂推理、多跳问题
   - 覆盖不同主题: 确保知识库的各个领域都有覆盖
   - 包含边界情况: 知识库中不存在答案的问题

2. **编写标准答案**:
   - 标注答案来源 (哪个文档的哪个段落)
   - 标注关键信息点 (用于评估召回率)

3. **⭐ 自动化评估脚本**:
```python
# 示例: RAG 评估脚本
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy

# Golden Dataset
golden_qa = [
    {"question": "如何优化 RAG 检索?", "answer": "使用 Parent-Child 索引", "context": "..."},
    # ... 更多问答对
]

# 运行评估
results = evaluate(golden_qa, metrics=[faithfulness, answer_relevancy])
print(f"Faithfulness: {results['faithfulness']:.2f}")
print(f"Answer Relevancy: {results['answer_relevancy']:.2f}")

# 如果分数 < 0.7,说明 RAG 链路需要优化
assert results['faithfulness'] > 0.7, "RAG 忠实度不足"
```

**集成到 CI/CD** (实现评估左移):

**目标**: 将 RAG 评估视为单元测试,每次修改自动验证质量

**实施步骤**:
1. **创建评估脚本**: 将上述 RAG 评估代码保存为 `tests/test_rag_quality.py`
2. ⭐ **设置质量门槛**: 定义最低可接受分数 (Faithfulness > 0.7, Answer Relevancy > 0.7)
3. **集成 CI 流程**: 在 GitHub Actions / GitLab CI 中添加评估步骤

**CI 配置示例** (GitHub Actions):
```yaml
# .github/workflows/rag-quality.yml
name: RAG Quality Check
on: [push, pull_request]
jobs:
  evaluate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Run RAG Evaluation
        run: |
          python tests/test_rag_quality.py
          # 如果分数低于门槛,CI 失败
```

**使用 Ragas 或 TruLens**:
- ⭐ **Ragas**: 更适合 RAG 系统,提供 Faithfulness, Answer Relevancy 等指标
- **TruLens**: 更适合复杂 Agent,提供完整的 Trace 分析

**效果验证**: 修改 Prompt 后,CI 自动运行评估,如果 Faithfulness 下降超过 5%,自动阻止合并

## ⭐ 核心能力 2: 异构系统通信协议 (Java ↔ Python)

### 核心挑战

1. **AI 推理很慢 (Python),业务逻辑很快 (Java)** → 需要异步解耦
2. ⭐ **Java 需要确定的 JSON 对象,LLM 输出不稳定** → 需要结构化输出验证
3. **跨语言数据一致性** → 需要统一的数据契约

### 架构设计: 三层解决方案

**⭐ 1. 结构化输出验证**

Python 端:
```python
from pydantic import BaseModel
from instructor import patch

class UserInfo(BaseModel):
    user_id: str
    email: str
    profile: dict

# 强制 LLM 输出符合 Pydantic 模型
client = patch(OpenAI())
response = client.chat.completions.create(
    model="gpt-4",
    response_model=UserInfo,
    messages=[{"role": "user", "content": "Extract user info from: ..."}]
)
# response 保证是 UserInfo 类型
```

Java 端:
```java
// 使用 OpenAPI/Swagger 生成对应的 DTO
@Data
public class UserInfo {
    private String userId;
    private String email;
    private Map<String, Object> profile;
}
```

**⭐ 2. 异步通信模式 (Sidecar Pattern)**

架构图:
```
用户请求 → Java 后端 (业务逻辑) → 返回 "处理中"
              ↓
         消息队列 (RabbitMQ)
              ↓
    Python 服务 (AI 推理) → 处理完成
              ↓
         回调 Java (更新状态)
```

实战场景:
- 用户上传 PDF 后,Java 后端直接返回"处理中"
- 通过 MQ 通知 Python 服务进行切片、向量化
- 处理完成后回调 Java 更新状态

**3. 数据契约定义 (OpenAPI/Swagger)**

```yaml
# shared-api-spec.yaml
components:
  schemas:
    RAGRequest:
      type: object
      properties:
        query:
          type: string
        top_k:
          type: integer
          default: 5
    RAGResponse:
      type: object
      properties:
        answer:
          type: string
        sources:
          type: array
          items:
            type: string
        confidence:
          type: number
```

Java 端使用 OpenAPI Generator 生成 Feign Client:
```java
@FeignClient(name = "rag-service", url = "${rag.service.url}")
public interface RAGServiceClient {
    @PostMapping("/query")
    RAGResponse query(@RequestBody RAGRequest request);
}
```

### 混合搜索策略

不仅使用向量搜索,组合**全文搜索 (Elasticsearch/MySQL)** 与 **向量搜索 (Milvus)**:

```python
# 混合搜索示例
def hybrid_search(query: str, top_k: int = 5):
    # 1. 向量搜索 (语义相似)
    vector_results = milvus_client.search(query_embedding, top_k=10)
    
    # 2. 全文搜索 (关键词匹配)
    keyword_results = elasticsearch.search(query, top_k=10)
    
    # 3. 融合结果 (Reciprocal Rank Fusion)
    final_results = rrf_fusion(vector_results, keyword_results, top_k=top_k)
    
    return final_results
```

## 核心能力 3: 双库架构设计

**架构**: MySQL (业务数据) + Vector DB (语义数据)

**数据同步一致性问题**:

```java
// Java 端: 创建用户时同步到向量库
@Transactional
public void createUser(User user) {
    // 1. 保存到 MySQL
    userRepository.save(user);
    
    // 2. 发送事件到 MQ (异步同步到向量库)
    rabbitTemplate.convertAndSend("user.created", new UserCreatedEvent(user));
}
```

```python
# Python 端: 监听 MQ,同步到向量库
@mq_consumer("user.created")
def sync_user_to_vector_db(event: UserCreatedEvent):
    embedding = embed_model.encode(event.user.profile)
    milvus_client.insert({
        "user_id": event.user.id,
        "embedding": embedding,
        "metadata": event.user.to_dict()
    })
```

## 阶段产出标准

**必须完成的交付物** (作为进入 Level 3 的前置条件):

**RAG 应用层**:
- [X] 完成 Dify 部署并发布至少 1 个知识库应用,能够回答领域问题
- [ ] Dify 自定义工具
- [ ] ⭐ 手写完整 RAG 链路代码,包含: PDF 解析 → 切片 → 向量化 → Milvus 存储 → 检索 → LLM 生成
- [ ] ⭐ 实现至少 1 种高级切片策略 (Parent-Child 或 HyDE),并通过对比实验验证效果

**评估体系层**:
- [ ] ⭐ 建立 Golden Dataset (10-20 个问答对),包含不同难度和主题的问题
- [ ] ⭐ 实现自动化评估脚本,集成 Ragas 或 TruLens
- [ ] **量化指标**: 使用 Golden Dataset 测试,召回率从基线提升至少 20% (例如从 0.60 提升到 0.72),Faithfulness > 0.7

**异构系统架构层**:
- [ ] ⭐ 设计并实现 Java-Python 异步通信架构 (使用 RabbitMQ 或 Kafka)
- [ ] 实现混合搜索策略 (向量 + 全文),并通过 A/B 测试验证效果提升
- [ ] 定义统一的 OpenAPI 数据契约,Java 端能够通过 Feign Client 调用 Python 服务

**能力验证**:
- [ ] ⭐ 能够解释 "Parent-Child Indexing 为什么比普通切片更好" 并给出数据支持
- [ ] 能够设计一个完整的双库架构 (MySQL + Milvus),并解决数据同步一致性问题

**时间检查点**: 如果超过 3 周仍未完成,建议先使用 Dify 完成基础 RAG,再逐步添加高级功能

## 路线图优化建议

**实战项目**: 在 Java 中构建"搜索切换器",根据问题类型自动决定:
- 使用数据库查询 (结构化数据,如"查询用户订单")
- 使用 RAG 查询 (非结构化知识,如"如何优化系统性能")

---

**上一阶段**: [Level 1 - AI-Native 工作流与基础设施](./level-1-ai-native)

**下一阶段**: [Level 3 - Agent 架构与可观测性](./level-3-agent)
